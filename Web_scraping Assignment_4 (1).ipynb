{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7002a967",
   "metadata": {},
   "source": [
    "# NAME - ADITYA JAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de13f0b",
   "metadata": {},
   "source": [
    "# BATCH NO. DS2310"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57dd2ec",
   "metadata": {},
   "source": [
    "**Question 1**- Scrape the details of most viewed videos on YouTube from Wikipedia. Url\n",
    "= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details:\n",
    "1 Rank\n",
    "2 Name\n",
    "3 Artist\n",
    "4 Upload date\n",
    "5 Views "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feb04fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nessesary library\n",
    "import selenium\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "443423c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the wikipedia page on automated chrome browser\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e89d872",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos#Top_videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bf5adad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty enumerate for store details\n",
    "name = []\n",
    "artist = []\n",
    "views = []\n",
    "upload_date = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d524f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping name\n",
    "nam = driver.find_elements(By.XPATH,'//div[@id=\"mw-content-text\"]/div[1]/table[1]/tbody/tr/td[1]')\n",
    "for i in nam:\n",
    "    name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9835e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping artists\n",
    "artis = driver.find_elements(By.XPATH,'//div[@id=\"mw-content-text\"]/div[1]/table[1]/tbody/tr/td[2]')\n",
    "for i in artis:\n",
    "    artist.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c811e119",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = driver.find_elements(By.XPATH,'//div[@id=\"mw-content-text\"]/div[1]/table[1]/tbody/tr/td[3]')\n",
    "for i in view:\n",
    "    views.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57531ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "upd = driver.find_elements(By.XPATH,'//div[@id=\"mw-content-text\"]/div[1]/table[1]/tbody/tr/td[4]')\n",
    "for i in upd:\n",
    "    upload_date.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a0e508d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30\n"
     ]
    }
   ],
   "source": [
    "# print len\n",
    "print(len(name),len(artist),len(views),len(upload_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63837bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Artists</th>\n",
       "      <th>Views</th>\n",
       "      <th>Upload_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>13.78</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.33</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Johny Johny Yes Papa\"[17]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>6.85</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Bath Song\"[18]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>6.52</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Shape of You\"[19]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>6.15</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"See You Again\"[22]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>6.11</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Wheels on the Bus\"[27]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>5.74</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Phonics Song with Two Words\"[28]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>5.59</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Uptown Funk\"[29]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>5.10</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[30]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>5.03</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.98</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[36]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.57</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>4.49</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"Axel F\"[38]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>4.19</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"Sugar\"[39]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.97</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"Counting Stars\"[40]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.93</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"Roar\"[41]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.92</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"Baa Baa Black Sheep\"[42]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>3.86</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[43]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.80</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"Lakdi Ki Kathi\"[44]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>3.78</td>\n",
       "      <td>June 14, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\"Sorry\"[45]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.74</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\"Thinking Out Loud\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.70</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\"Humpty the train on a fruits ride\"[47]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.65</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\"Dark Horse\"[48]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.64</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\"Perfect\"[49]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.61</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>\"Shree Hanuman Chalisa\"[50]</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>3.57</td>\n",
       "      <td>May 10, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\"Let Her Go\"[51]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.57</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\"Faded\"[52]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.56</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\"Girls Like You\"[53]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.53</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\"Lean On\"[54]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>3.51</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Name  \\\n",
       "0                             \"Baby Shark Dance\"[6]   \n",
       "1                                    \"Despacito\"[9]   \n",
       "2                        \"Johny Johny Yes Papa\"[17]   \n",
       "3                                   \"Bath Song\"[18]   \n",
       "4                                \"Shape of You\"[19]   \n",
       "5                               \"See You Again\"[22]   \n",
       "6                           \"Wheels on the Bus\"[27]   \n",
       "7                 \"Phonics Song with Two Words\"[28]   \n",
       "8                                 \"Uptown Funk\"[29]   \n",
       "9   \"Learning Colors – Colorful Eggs on a Farm\"[30]   \n",
       "10                              \"Gangnam Style\"[31]   \n",
       "11   \"Masha and the Bear – Recipe for Disaster\"[36]   \n",
       "12                             \"Dame Tu Cosita\"[37]   \n",
       "13                                     \"Axel F\"[38]   \n",
       "14                                      \"Sugar\"[39]   \n",
       "15                             \"Counting Stars\"[40]   \n",
       "16                                       \"Roar\"[41]   \n",
       "17                        \"Baa Baa Black Sheep\"[42]   \n",
       "18           \"Waka Waka (This Time for Africa)\"[43]   \n",
       "19                             \"Lakdi Ki Kathi\"[44]   \n",
       "20                                      \"Sorry\"[45]   \n",
       "21                          \"Thinking Out Loud\"[46]   \n",
       "22          \"Humpty the train on a fruits ride\"[47]   \n",
       "23                                 \"Dark Horse\"[48]   \n",
       "24                                    \"Perfect\"[49]   \n",
       "25                      \"Shree Hanuman Chalisa\"[50]   \n",
       "26                                 \"Let Her Go\"[51]   \n",
       "27                                      \"Faded\"[52]   \n",
       "28                             \"Girls Like You\"[53]   \n",
       "29                                    \"Lean On\"[54]   \n",
       "\n",
       "                                              Artists  Views  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories  13.78   \n",
       "1                                          Luis Fonsi   8.33   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs   6.85   \n",
       "3                          Cocomelon - Nursery Rhymes   6.52   \n",
       "4                                          Ed Sheeran   6.15   \n",
       "5                                         Wiz Khalifa   6.11   \n",
       "6                          Cocomelon - Nursery Rhymes   5.74   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs   5.59   \n",
       "8                                         Mark Ronson   5.10   \n",
       "9                                         Miroshka TV   5.03   \n",
       "10                                                Psy   4.98   \n",
       "11                                         Get Movies   4.57   \n",
       "12                                      Ultra Records   4.49   \n",
       "13                                         Crazy Frog   4.19   \n",
       "14                                           Maroon 5   3.97   \n",
       "15                                        OneRepublic   3.93   \n",
       "16                                         Katy Perry   3.92   \n",
       "17                         Cocomelon - Nursery Rhymes   3.86   \n",
       "18                                            Shakira   3.80   \n",
       "19                                       Jingle Toons   3.78   \n",
       "20                                      Justin Bieber   3.74   \n",
       "21                                         Ed Sheeran   3.70   \n",
       "22      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   3.65   \n",
       "23                                         Katy Perry   3.64   \n",
       "24                                         Ed Sheeran   3.61   \n",
       "25                              T-Series Bhakti Sagar   3.57   \n",
       "26                                          Passenger   3.57   \n",
       "27                                        Alan Walker   3.56   \n",
       "28                                           Maroon 5   3.53   \n",
       "29                               Major Lazer Official   3.51   \n",
       "\n",
       "          Upload_date  \n",
       "0       June 17, 2016  \n",
       "1    January 12, 2017  \n",
       "2     October 8, 2016  \n",
       "3         May 2, 2018  \n",
       "4    January 30, 2017  \n",
       "5       April 6, 2015  \n",
       "6        May 24, 2018  \n",
       "7       March 6, 2014  \n",
       "8   November 19, 2014  \n",
       "9   February 27, 2018  \n",
       "10      July 15, 2012  \n",
       "11   January 31, 2012  \n",
       "12      April 5, 2018  \n",
       "13      June 16, 2009  \n",
       "14   January 14, 2015  \n",
       "15       May 31, 2013  \n",
       "16  September 5, 2013  \n",
       "17      June 25, 2018  \n",
       "18       June 4, 2010  \n",
       "19      June 14, 2018  \n",
       "20   October 22, 2015  \n",
       "21    October 7, 2014  \n",
       "22   January 26, 2018  \n",
       "23  February 20, 2014  \n",
       "24   November 9, 2017  \n",
       "25       May 10, 2011  \n",
       "26      July 25, 2012  \n",
       "27   December 3, 2015  \n",
       "28       May 31, 2018  \n",
       "29     March 22, 2015  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe\n",
    "data=pd.DataFrame({})\n",
    "data['Name']= name\n",
    "data['Artists']= artist\n",
    "data['Views']= views\n",
    "data['Upload_date']= upload_date\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "587d8cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a019dbd",
   "metadata": {},
   "source": [
    "**Question 2**- Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Series\n",
    "B) Place\n",
    "C) Date\n",
    "D) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02a70052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import selenium\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebb284a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the bcci.tv page on automated chrome browser\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f983a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.bcci.tv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66158ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixture = driver.find_element(By.XPATH,'/html/body/header/div[3]/div[2]/ul/div[1]/a[2]')\n",
    "fixture.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67467ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "more = driver.find_element(By.XPATH,'/html/body/section/div/div/div/div/div/div[2]/div[2]/div[2]/div/button')\n",
    "more.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c59ab271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty enumerate for store details\n",
    "series = []\n",
    "place = []\n",
    "date = []\n",
    "time= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a074857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping series name\n",
    "ser = driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "for i in ser:\n",
    "    series.append(i.text)\n",
    "    \n",
    "# scraping place\n",
    "pla = driver.find_elements(By.XPATH,'')\n",
    "for a in pla:\n",
    "    place.append(a.text)\n",
    "    \n",
    "# scraping date\n",
    "dates = driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')\n",
    "for b in dates:\n",
    "    date.append(b.text)\n",
    "    \n",
    "# scraping time\n",
    "times = driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "for c in times:\n",
    "    time.append(c.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3aac3867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>SuperSport Park, Centurion</td>\n",
       "      <td>26 DECEMBER, 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2023-24</td>\n",
       "      <td>Wankhede Stadium, Mumbai</td>\n",
       "      <td>28 DECEMBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2023-24</td>\n",
       "      <td>Wankhede Stadium, Mumbai</td>\n",
       "      <td>30 DECEMBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2023-24</td>\n",
       "      <td>Wankhede Stadium, Mumbai</td>\n",
       "      <td>2 JANUARY, 2024</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>Newlands, Cape Town</td>\n",
       "      <td>3 JANUARY, 2024</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2023-24</td>\n",
       "      <td>DY Patil Stadium, NAVI MUMBAI</td>\n",
       "      <td>5 JANUARY, 2024</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2023-24</td>\n",
       "      <td>DY Patil Stadium, NAVI MUMBAI</td>\n",
       "      <td>7 JANUARY, 2024</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2023-24</td>\n",
       "      <td>DY Patil Stadium, NAVI MUMBAI</td>\n",
       "      <td>9 JANUARY, 2024</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AFGHANISTAN TOUR OF INDIA 2023-24</td>\n",
       "      <td>Punjab Cricket Association IS Bindra Stadium, ...</td>\n",
       "      <td>11 JANUARY, 2024</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AFGHANISTAN TOUR OF INDIA 2023-24</td>\n",
       "      <td>Holkar Cricket Stadium, Indore</td>\n",
       "      <td>14 JANUARY, 2024</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AFGHANISTAN TOUR OF INDIA 2023-24</td>\n",
       "      <td>M Chinnaswamy Stadium, Bengaluru</td>\n",
       "      <td>17 JANUARY, 2024</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>Rajiv Gandhi International Stadium, Hyderabad</td>\n",
       "      <td>25 JANUARY, 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadi...</td>\n",
       "      <td>2 FEBRUARY, 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>Saurashtra Cricket Association Stadium, Rajkot</td>\n",
       "      <td>15 FEBRUARY, 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>JSCA International Stadium Complex, Ranchi</td>\n",
       "      <td>23 FEBRUARY, 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>Himachal Pradesh Cricket Association Stadium, ...</td>\n",
       "      <td>7 MARCH, 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Series  \\\n",
       "0      INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "1   AUSTRALIA WOMEN TOUR OF INDIA 2023-24   \n",
       "2   AUSTRALIA WOMEN TOUR OF INDIA 2023-24   \n",
       "3   AUSTRALIA WOMEN TOUR OF INDIA 2023-24   \n",
       "4      INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "5   AUSTRALIA WOMEN TOUR OF INDIA 2023-24   \n",
       "6   AUSTRALIA WOMEN TOUR OF INDIA 2023-24   \n",
       "7   AUSTRALIA WOMEN TOUR OF INDIA 2023-24   \n",
       "8       AFGHANISTAN TOUR OF INDIA 2023-24   \n",
       "9       AFGHANISTAN TOUR OF INDIA 2023-24   \n",
       "10      AFGHANISTAN TOUR OF INDIA 2023-24   \n",
       "11          ENGLAND TOUR OF INDIA 2023-24   \n",
       "12          ENGLAND TOUR OF INDIA 2023-24   \n",
       "13          ENGLAND TOUR OF INDIA 2023-24   \n",
       "14          ENGLAND TOUR OF INDIA 2023-24   \n",
       "15          ENGLAND TOUR OF INDIA 2023-24   \n",
       "\n",
       "                                                Place               Date  \\\n",
       "0                          SuperSport Park, Centurion  26 DECEMBER, 2023   \n",
       "1                            Wankhede Stadium, Mumbai  28 DECEMBER, 2023   \n",
       "2                            Wankhede Stadium, Mumbai  30 DECEMBER, 2023   \n",
       "3                            Wankhede Stadium, Mumbai    2 JANUARY, 2024   \n",
       "4                                 Newlands, Cape Town    3 JANUARY, 2024   \n",
       "5                       DY Patil Stadium, NAVI MUMBAI    5 JANUARY, 2024   \n",
       "6                       DY Patil Stadium, NAVI MUMBAI    7 JANUARY, 2024   \n",
       "7                       DY Patil Stadium, NAVI MUMBAI    9 JANUARY, 2024   \n",
       "8   Punjab Cricket Association IS Bindra Stadium, ...   11 JANUARY, 2024   \n",
       "9                      Holkar Cricket Stadium, Indore   14 JANUARY, 2024   \n",
       "10                   M Chinnaswamy Stadium, Bengaluru   17 JANUARY, 2024   \n",
       "11      Rajiv Gandhi International Stadium, Hyderabad   25 JANUARY, 2024   \n",
       "12  Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadi...   2 FEBRUARY, 2024   \n",
       "13     Saurashtra Cricket Association Stadium, Rajkot  15 FEBRUARY, 2024   \n",
       "14         JSCA International Stadium Complex, Ranchi  23 FEBRUARY, 2024   \n",
       "15  Himachal Pradesh Cricket Association Stadium, ...      7 MARCH, 2024   \n",
       "\n",
       "           Time  \n",
       "0   1:30 PM IST  \n",
       "1   2:00 PM IST  \n",
       "2   2:00 PM IST  \n",
       "3   2:00 PM IST  \n",
       "4   1:30 PM IST  \n",
       "5   7:00 PM IST  \n",
       "6   7:00 PM IST  \n",
       "7   7:00 PM IST  \n",
       "8   7:00 PM IST  \n",
       "9   7:00 PM IST  \n",
       "10  7:00 PM IST  \n",
       "11  9:30 AM IST  \n",
       "12  9:30 AM IST  \n",
       "13  9:30 AM IST  \n",
       "14  9:30 AM IST  \n",
       "15  9:30 AM IST  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe\n",
    "data=pd.DataFrame({})\n",
    "data['Series']= series\n",
    "data['Place']= place\n",
    "data['Date']= date\n",
    "data['Time']= time\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0106379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee6156f",
   "metadata": {},
   "source": [
    "**Question 3**- Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details: A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c1ccf2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import selenium\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "159e8e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the statisticstimes page on automated chrome browser\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "df7aff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"http://statisticstimes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1bf5e31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eco = driver.find_element(By.XPATH,'//*[@id=\"top\"]/div[2]/div[2]/button')\n",
    "eco.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a66a1988",
   "metadata": {},
   "outputs": [],
   "source": [
    "india = driver.find_element(By.XPATH,'//*[@id=\"top\"]/div[2]/div[2]/div/a[3]')\n",
    "india.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "653717cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "select = driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "select.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ba2a8689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty enumerate for store details\n",
    "rank = []\n",
    "state = []\n",
    "gsdp_1 = []\n",
    "gsdp_2= []\n",
    "share = []\n",
    "gdp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2b7c500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap rank\n",
    "rnk = driver.find_elements(By.XPATH,'//td[@class=\"data1\"]')\n",
    "for i in rnk:\n",
    "    rank.append(i.text)\n",
    "        \n",
    "# scraping state\n",
    "states = driver.find_elements(By.XPATH,'//td[@class=\"name\"]')\n",
    "for a in states:\n",
    "    if a.text is None:\n",
    "        state.append(\"--\")\n",
    "    else:\n",
    "        state.append(a.text)\n",
    "        \n",
    "# scrap current gsdp\n",
    "\n",
    "current = driver.find_elements(By.XPATH,\"//*[@id='table_id']/tbody/tr/td[3]\")\n",
    "for b in current:\n",
    "    if b.text is None:\n",
    "        gsdp_1.append(\"--\")\n",
    "    else:\n",
    "        gsdp_1.append(b.text)\n",
    "        \n",
    "# scrap previous gsdp\n",
    "\n",
    "previous = driver.find_elements(By.XPATH,\"//*[@id='table_id']/tbody/tr/td[4]\")\n",
    "for c in previous:\n",
    "    if c.text is None:\n",
    "        gsdp_2.append(\"--\")\n",
    "    else:\n",
    "        gsdp_2.append(c.text)\n",
    "        \n",
    "# scrap share\n",
    "sh = driver.find_elements(By.XPATH,\"//*[@id='table_id']/tbody/tr/td[5]\")\n",
    "for d in sh:\n",
    "    if d.text is None:\n",
    "        share.append(\"--\")\n",
    "    else:\n",
    "        share.append(d.text)\n",
    "        \n",
    "\n",
    "# scrap gdp in dollar\n",
    "gd = driver.find_elements(By.XPATH,\"//*[@id='table_id']/tbody/tr/td[6]\")\n",
    "for e in gd:\n",
    "    if e.text is None:\n",
    "        gdp.append(\"--\")\n",
    "    else:\n",
    "        gdp.append(e.text)        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "95dfd364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>Current_GSDP</th>\n",
       "      <th>Previous_GSDP</th>\n",
       "      <th>Share</th>\n",
       "      <th>GDP In Dollar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>3,108,022</td>\n",
       "      <td>13.24%</td>\n",
       "      <td>417.163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>2,364,514</td>\n",
       "      <td>2,071,286</td>\n",
       "      <td>8.82%</td>\n",
       "      <td>278.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>2,257,575</td>\n",
       "      <td>1,974,532</td>\n",
       "      <td>8.41%</td>\n",
       "      <td>265.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>2,241,368</td>\n",
       "      <td>1,962,725</td>\n",
       "      <td>8.36%</td>\n",
       "      <td>263.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,937,066</td>\n",
       "      <td>8.25%</td>\n",
       "      <td>259.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,554,992</td>\n",
       "      <td>1,363,926</td>\n",
       "      <td>5.81%</td>\n",
       "      <td>183.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,413,620</td>\n",
       "      <td>1,218,193</td>\n",
       "      <td>5.19%</td>\n",
       "      <td>163.507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>1,322,821</td>\n",
       "      <td>1,136,137</td>\n",
       "      <td>4.84%</td>\n",
       "      <td>152.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>1,317,728</td>\n",
       "      <td>1,133,837</td>\n",
       "      <td>4.83%</td>\n",
       "      <td>152.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>1,313,391</td>\n",
       "      <td>1,128,907</td>\n",
       "      <td>4.81%</td>\n",
       "      <td>151.523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>932,470</td>\n",
       "      <td>3.97%</td>\n",
       "      <td>125.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>1,043,759</td>\n",
       "      <td>904,642</td>\n",
       "      <td>3.85%</td>\n",
       "      <td>121.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>994,154</td>\n",
       "      <td>870,665</td>\n",
       "      <td>3.71%</td>\n",
       "      <td>116.862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>774,869</td>\n",
       "      <td>670,881</td>\n",
       "      <td>2.86%</td>\n",
       "      <td>90.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>751,396</td>\n",
       "      <td>650,302</td>\n",
       "      <td>2.77%</td>\n",
       "      <td>87.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>673,107</td>\n",
       "      <td>614,227</td>\n",
       "      <td>2.62%</td>\n",
       "      <td>82.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>493,167</td>\n",
       "      <td>412,612</td>\n",
       "      <td>1.76%</td>\n",
       "      <td>55.381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>457,608</td>\n",
       "      <td>406,416</td>\n",
       "      <td>1.73%</td>\n",
       "      <td>54.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>393,722</td>\n",
       "      <td>358,863</td>\n",
       "      <td>1.53%</td>\n",
       "      <td>48.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>302,621</td>\n",
       "      <td>272,159</td>\n",
       "      <td>1.16%</td>\n",
       "      <td>36.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir-UT</td>\n",
       "      <td>227,927</td>\n",
       "      <td>199,917</td>\n",
       "      <td>0.85%</td>\n",
       "      <td>26.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>195,405</td>\n",
       "      <td>176,269</td>\n",
       "      <td>0.75%</td>\n",
       "      <td>23.659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>-</td>\n",
       "      <td>82,604</td>\n",
       "      <td>0.35%</td>\n",
       "      <td>11.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>72,636</td>\n",
       "      <td>62,550</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>8.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>45,635</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>6.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>-</td>\n",
       "      <td>44,238</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>5.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>42,697</td>\n",
       "      <td>38,785</td>\n",
       "      <td>0.17%</td>\n",
       "      <td>5.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>42,756</td>\n",
       "      <td>37,557</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>5.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>-</td>\n",
       "      <td>36,594</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>4.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>35,124</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>31,913</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>-</td>\n",
       "      <td>27,824</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>10,371</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>1.392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State Current_GSDP Previous_GSDP   Share  \\\n",
       "0     1                Maharashtra            -     3,108,022  13.24%   \n",
       "1     2                 Tamil Nadu    2,364,514     2,071,286   8.82%   \n",
       "2     3              Uttar Pradesh    2,257,575     1,974,532   8.41%   \n",
       "3     4                  Karnataka    2,241,368     1,962,725   8.36%   \n",
       "4     5                    Gujarat            -     1,937,066   8.25%   \n",
       "5     6                West Bengal    1,554,992     1,363,926   5.81%   \n",
       "6     7                  Rajasthan    1,413,620     1,218,193   5.19%   \n",
       "7     8             Madhya Pradesh    1,322,821     1,136,137   4.84%   \n",
       "8     9             Andhra Pradesh    1,317,728     1,133,837   4.83%   \n",
       "9    10                  Telangana    1,313,391     1,128,907   4.81%   \n",
       "10   11                     Kerala            -       932,470   3.97%   \n",
       "11   12                      Delhi    1,043,759       904,642   3.85%   \n",
       "12   13                    Haryana      994,154       870,665   3.71%   \n",
       "13   14                     Odisha      774,869       670,881   2.86%   \n",
       "14   15                      Bihar      751,396       650,302   2.77%   \n",
       "15   16                     Punjab      673,107       614,227   2.62%   \n",
       "16   17                      Assam      493,167       412,612   1.76%   \n",
       "17   18               Chhattisgarh      457,608       406,416   1.73%   \n",
       "18   19                  Jharkhand      393,722       358,863   1.53%   \n",
       "19   20                Uttarakhand      302,621       272,159   1.16%   \n",
       "20   21         Jammu & Kashmir-UT      227,927       199,917   0.85%   \n",
       "21   22           Himachal Pradesh      195,405       176,269   0.75%   \n",
       "22   23                        Goa            -        82,604   0.35%   \n",
       "23   24                    Tripura       72,636        62,550   0.27%   \n",
       "24   25                 Chandigarh            -        45,635   0.19%   \n",
       "25   26                 Puducherry            -        44,238   0.19%   \n",
       "26   27                  Meghalaya       42,697        38,785   0.17%   \n",
       "27   28                     Sikkim       42,756        37,557   0.16%   \n",
       "28   29                    Manipur            -        36,594   0.16%   \n",
       "29   30          Arunachal Pradesh            -        35,124   0.15%   \n",
       "30   31                   Nagaland            -        31,913   0.14%   \n",
       "31   32                    Mizoram            -        27,824   0.12%   \n",
       "32   33  Andaman & Nicobar Islands            -        10,371   0.04%   \n",
       "\n",
       "   GDP In Dollar  \n",
       "0        417.163  \n",
       "1        278.011  \n",
       "2        265.024  \n",
       "3        263.440  \n",
       "4        259.996  \n",
       "5        183.068  \n",
       "6        163.507  \n",
       "7        152.494  \n",
       "8        152.185  \n",
       "9        151.523  \n",
       "10       125.157  \n",
       "11       121.422  \n",
       "12       116.862  \n",
       "13        90.047  \n",
       "14        87.284  \n",
       "15        82.442  \n",
       "16        55.381  \n",
       "17        54.550  \n",
       "18        48.167  \n",
       "19        36.530  \n",
       "20        26.833  \n",
       "21        23.659  \n",
       "22        11.087  \n",
       "23         8.396  \n",
       "24         6.125  \n",
       "25         5.938  \n",
       "26         5.206  \n",
       "27         5.041  \n",
       "28         4.912  \n",
       "29         4.714  \n",
       "30         4.283  \n",
       "31         3.735  \n",
       "32         1.392  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe\n",
    "data=pd.DataFrame({})\n",
    "data['Rank']= rank[:33]\n",
    "data['State']= state[:33]\n",
    "data['Current_GSDP']= gsdp_1[:33]\n",
    "data['Previous_GSDP']= gsdp_2[:33]\n",
    "data['Share']= share[:33]\n",
    "data['GDP In Dollar']=gdp[:33]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aa85f8",
   "metadata": {},
   "source": [
    "**Question 4**- Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e5048064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import selenium\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8566c999",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the github page on automated chrome browser\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1cafd5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://github.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "efea9e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')\n",
    "explore.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ba550c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trending = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')\n",
    "trending.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f12ddb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty enumerate for store details\n",
    "title = []\n",
    "description = []\n",
    "counts = []\n",
    "language = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cac1d98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap repository title\n",
    "tit = driver.find_elements(By.XPATH,'//h2[@class=\"h3 lh-condensed\"]//a')\n",
    "for i in tit:\n",
    "    if i.text is None:\n",
    "        title.append(\"--\")\n",
    "    else:\n",
    "        title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "04d39c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap description\n",
    "des = driver.find_elements(By.XPATH,'//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "for a in des:\n",
    "    if a.text is None:\n",
    "        description.append(\"--\")\n",
    "    else:\n",
    "        description.append(a.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c998e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap contributors\n",
    "count = driver.find_elements(By.XPATH,'//a[@class=\"Link Link--muted d-inline-block mr-3\"]')\n",
    "for b in count:\n",
    "    if b.text is None:\n",
    "        counts.append(\"--\")\n",
    "    else:\n",
    "        counts.append(b.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d32c37f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Contributors_count=[]\n",
    "for i in range(1,len(counts),2):\n",
    "    Contributors_count.append(counts[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e432f9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap language\n",
    "lang = driver.find_elements(By.XPATH,'//span[@itemprop=\"programmingLanguage\"]')\n",
    "for c in lang:\n",
    "    language.append(c.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "62100272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cumulo-autumn / StreamDiffusion</td>\n",
       "      <td>StreamDiffusion: A Pipeline-Level Solution for...</td>\n",
       "      <td>178</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apple / ml-ferret</td>\n",
       "      <td>完全免费开源，基于 Requests 模块实现：TikTok 主页/视频/图集/原声；抖音主...</td>\n",
       "      <td>104</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JoeanAmier / TikTokDownloader</td>\n",
       "      <td>Dev tool that writes scalable apps from scratc...</td>\n",
       "      <td>341</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pythagora-io / gpt-pilot</td>\n",
       "      <td>Community designed ERCF v2</td>\n",
       "      <td>1,437</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Enraged-Rabbit-Community / ERCF_v2</td>\n",
       "      <td>GUI-focused roop</td>\n",
       "      <td>16</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hillobar / Rope</td>\n",
       "      <td>AppAgent: Multimodal Agents as Smartphone User...</td>\n",
       "      <td>179</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mnotgod96 / AppAgent</td>\n",
       "      <td>A dedicated scratchpad for developers</td>\n",
       "      <td>116</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>heyman / heynote</td>\n",
       "      <td>A unified evaluation framework for large langu...</td>\n",
       "      <td>44</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>microsoft / promptbench</td>\n",
       "      <td>📜 A minimalist personal website embodying the ...</td>\n",
       "      <td>47</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Innei / Shiro</td>\n",
       "      <td>A curated list of Large Language Model (LLM) I...</td>\n",
       "      <td>174</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>JShollaj / awesome-llm-interpretability</td>\n",
       "      <td>G-code generator for 3D printers (Bambu, Prusa...</td>\n",
       "      <td>30</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SoftFever / OrcaSlicer</td>\n",
       "      <td>An Open-Source Assistants API and GPTs alterna...</td>\n",
       "      <td>381</td>\n",
       "      <td>Ruby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>langgenius / dify</td>\n",
       "      <td>A curated list of engineering blogs</td>\n",
       "      <td>1,693</td>\n",
       "      <td>Kotlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>kilimchoi / engineering-blogs</td>\n",
       "      <td>This repository contains everything you need t...</td>\n",
       "      <td>1,193</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Coder-World04 / Complete-System-Design</td>\n",
       "      <td>The Z3 Theorem Prover</td>\n",
       "      <td>295</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>simondankelmann / Bluetooth-LE-Spam</td>\n",
       "      <td>Learn how to design systems at scale and prepa...</td>\n",
       "      <td>188</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Z3Prover / z3</td>\n",
       "      <td>A sound cloning tool with a web interface, usi...</td>\n",
       "      <td>1,431</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>karanpratapsingh / system-design</td>\n",
       "      <td>A one-of-a-kind resume builder that keeps your...</td>\n",
       "      <td>2,248</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>elifgazioglu / doyouwannagooutwithme</td>\n",
       "      <td>🏡 Open source home automation that puts local ...</td>\n",
       "      <td>73</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>jianchang512 / clone-voice</td>\n",
       "      <td>Versatile typeface for code, from code.</td>\n",
       "      <td>286</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Repository title  \\\n",
       "0           cumulo-autumn / StreamDiffusion   \n",
       "1                         apple / ml-ferret   \n",
       "2             JoeanAmier / TikTokDownloader   \n",
       "3                  Pythagora-io / gpt-pilot   \n",
       "4        Enraged-Rabbit-Community / ERCF_v2   \n",
       "5                           Hillobar / Rope   \n",
       "6                      mnotgod96 / AppAgent   \n",
       "7                          heyman / heynote   \n",
       "8                   microsoft / promptbench   \n",
       "9                             Innei / Shiro   \n",
       "10  JShollaj / awesome-llm-interpretability   \n",
       "11                   SoftFever / OrcaSlicer   \n",
       "12                        langgenius / dify   \n",
       "13            kilimchoi / engineering-blogs   \n",
       "14   Coder-World04 / Complete-System-Design   \n",
       "15      simondankelmann / Bluetooth-LE-Spam   \n",
       "16                            Z3Prover / z3   \n",
       "17         karanpratapsingh / system-design   \n",
       "18     elifgazioglu / doyouwannagooutwithme   \n",
       "19               jianchang512 / clone-voice   \n",
       "\n",
       "                               Repository description  Contributors count   \\\n",
       "0   StreamDiffusion: A Pipeline-Level Solution for...                  178   \n",
       "1   完全免费开源，基于 Requests 模块实现：TikTok 主页/视频/图集/原声；抖音主...                  104   \n",
       "2   Dev tool that writes scalable apps from scratc...                  341   \n",
       "3                          Community designed ERCF v2                1,437   \n",
       "4                                    GUI-focused roop                   16   \n",
       "5   AppAgent: Multimodal Agents as Smartphone User...                  179   \n",
       "6               A dedicated scratchpad for developers                  116   \n",
       "7   A unified evaluation framework for large langu...                   44   \n",
       "8   📜 A minimalist personal website embodying the ...                   47   \n",
       "9   A curated list of Large Language Model (LLM) I...                  174   \n",
       "10  G-code generator for 3D printers (Bambu, Prusa...                   30   \n",
       "11  An Open-Source Assistants API and GPTs alterna...                  381   \n",
       "12                A curated list of engineering blogs                1,693   \n",
       "13  This repository contains everything you need t...                1,193   \n",
       "14                              The Z3 Theorem Prover                  295   \n",
       "15  Learn how to design systems at scale and prepa...                  188   \n",
       "16  A sound cloning tool with a web interface, usi...                1,431   \n",
       "17  A one-of-a-kind resume builder that keeps your...                2,248   \n",
       "18  🏡 Open source home automation that puts local ...                   73   \n",
       "19            Versatile typeface for code, from code.                  286   \n",
       "\n",
       "      Language  \n",
       "0       Python  \n",
       "1       Python  \n",
       "2       Python  \n",
       "3       Python  \n",
       "4       Python  \n",
       "5       Python  \n",
       "6   JavaScript  \n",
       "7       Python  \n",
       "8   TypeScript  \n",
       "9          C++  \n",
       "10  TypeScript  \n",
       "11        Ruby  \n",
       "12      Kotlin  \n",
       "13         C++  \n",
       "14        HTML  \n",
       "15      Python  \n",
       "16  TypeScript  \n",
       "17      Python  \n",
       "18  JavaScript  \n",
       "19           C  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.DataFrame({})\n",
    "data['Repository title']= title[:20]\n",
    "data['Repository description']= description[:20]\n",
    "data[' Contributors count ']=  Contributors_count [:20]\n",
    "data['Language']= language[:20]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d020755",
   "metadata": {},
   "source": [
    "**Question 5**- Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the\n",
    "following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2529ade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import selenium\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "369a2c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the billboard page on automated chrome browser\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63a65047",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.billboard.com/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5e9c1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = driver.find_element(By.XPATH,'//*[@id=\"main-wrapper\"]/header/div/div[2]/div/div/div[1]/div[1]/button')\n",
    "bar.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4b0b79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100 = driver.find_element(By.XPATH,'//*[@id=\"main-wrapper\"]/div[9]/div/div/div/ul/li[1]/ul/li[2]/a')\n",
    "top_100.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d46355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty enumerates for store details\n",
    "song_name = []\n",
    "artist = []\n",
    "last_week_rank = []\n",
    "peak_rank = []\n",
    "week_on = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e15f068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap song name \n",
    "song = driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]//h3')\n",
    "for i in song:\n",
    "    song_name.append(i.text)\n",
    "    \n",
    "# scrap artist\n",
    "art = driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]//li[1]/span')\n",
    "for a in art:\n",
    "    artist.append(a.text)\n",
    "    \n",
    "# scrap last week rank\n",
    "last = driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]/li[4]')\n",
    "for b in last:\n",
    "    last_week_rank.append(b.text)\n",
    "    \n",
    "# scrap peak rank\n",
    "peak = driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]/li[5]')\n",
    "for c in peak:\n",
    "    peak_rank.append(c.text)\n",
    "    \n",
    "# scrap week on board\n",
    "week = driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]/li[4]')\n",
    "for d in week:\n",
    "    week_on.append(d.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53a9eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print len\n",
    "print(len(song_name),len(artist),len(last_week_rank),len(peak_rank),len(week_on))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7296e284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Last_week_rank</th>\n",
       "      <th>Peak_rank</th>\n",
       "      <th>Week_on_board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All I Want For Christmas Is You</td>\n",
       "      <td>Mariah Carey</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rockin' Around The Christmas Tree</td>\n",
       "      <td>Brenda Lee</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jingle Bell Rock</td>\n",
       "      <td>Bobby Helms</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Last Christmas</td>\n",
       "      <td>Wham!</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Holly Jolly Christmas</td>\n",
       "      <td>Burl Ives</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Save Me The Trouble</td>\n",
       "      <td>Dan + Shay</td>\n",
       "      <td>88</td>\n",
       "      <td>84</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Hey Driver</td>\n",
       "      <td>Zach Bryan Featuring The War And Treaty</td>\n",
       "      <td>86</td>\n",
       "      <td>14</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Virginia Beach</td>\n",
       "      <td>Drake</td>\n",
       "      <td>78</td>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Standing Next To You</td>\n",
       "      <td>Jung Kook</td>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Can't Have Mine</td>\n",
       "      <td>Dylan Scott</td>\n",
       "      <td>81</td>\n",
       "      <td>57</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Song  \\\n",
       "0     All I Want For Christmas Is You   \n",
       "1   Rockin' Around The Christmas Tree   \n",
       "2                    Jingle Bell Rock   \n",
       "3                      Last Christmas   \n",
       "4             A Holly Jolly Christmas   \n",
       "..                                ...   \n",
       "95                Save Me The Trouble   \n",
       "96                         Hey Driver   \n",
       "97                     Virginia Beach   \n",
       "98               Standing Next To You   \n",
       "99                    Can't Have Mine   \n",
       "\n",
       "                                     Artist Last_week_rank Peak_rank  \\\n",
       "0                              Mariah Carey              2         1   \n",
       "1                                Brenda Lee              1         1   \n",
       "2                               Bobby Helms              3         3   \n",
       "3                                     Wham!              4         4   \n",
       "4                                 Burl Ives              6         4   \n",
       "..                                      ...            ...       ...   \n",
       "95                               Dan + Shay             88        84   \n",
       "96  Zach Bryan Featuring The War And Treaty             86        14   \n",
       "97                                    Drake             78         3   \n",
       "98                                Jung Kook             72         5   \n",
       "99                              Dylan Scott             81        57   \n",
       "\n",
       "   Week_on_board  \n",
       "0              2  \n",
       "1              1  \n",
       "2              3  \n",
       "3              4  \n",
       "4              6  \n",
       "..           ...  \n",
       "95            88  \n",
       "96            86  \n",
       "97            78  \n",
       "98            72  \n",
       "99            81  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe\n",
    "data=pd.DataFrame({})\n",
    "data['Song']= song_name\n",
    "data['Artist']= artist\n",
    "data['Last_week_rank']= last_week_rank\n",
    "data['Peak_rank']= peak_rank\n",
    "data['Week_on_board']= week_on\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b31fb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ca5316",
   "metadata": {},
   "source": [
    "**Question 6**- Scrape the details of Highest selling novels.\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n",
    "Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "510db07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import selenium\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0a53e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the guardian.com page on automated chrome browser\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "748f6110",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1128d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty enurate for store details\n",
    "book_name = []\n",
    "author = []\n",
    "volume_sold = []\n",
    "publisher = []\n",
    "genre = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23f9ffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrap book name\n",
    "book = driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]//td[2]')\n",
    "for i in book:\n",
    "    book_name.append(i.text)\n",
    "    \n",
    "# scrap author name\n",
    "aut = driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]//td[3]')\n",
    "for a in aut:\n",
    "    author.append(a.text)\n",
    "    \n",
    "# scrap volume sold\n",
    "sold = driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]//td[4]')\n",
    "for b in sold:\n",
    "    volume_sold.append(b.text)\n",
    "    \n",
    "# scrap publisher\n",
    "publish = driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]//td[5]')\n",
    "for c in publish:\n",
    "    publisher.append(c.text)\n",
    "    \n",
    "# scrap genre\n",
    "gen = driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]//td[6]')\n",
    "for d in gen:\n",
    "    genre.append(d.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c50538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print len\n",
    "print(len(book_name),len(author),len(volume_sold),len(publisher),len(genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0664031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_Name</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Volume_Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book_Name           Authors  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume_Sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe\n",
    "data=pd.DataFrame({})\n",
    "data['Book_Name']= book_name\n",
    "data['Authors']= author\n",
    "data['Volume_Sold']= volume_sold\n",
    "data['Publisher']= publisher\n",
    "data['Genre']= genre\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfdced92",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62114229",
   "metadata": {},
   "source": [
    "**Question 7**- Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/ You have\n",
    "to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb7abfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import selenium\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23fdc1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the guardian.com page on automated chrome browser\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "98aafb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.imdb.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4cd7d4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu = driver.find_element(By.XPATH,'//*[@id=\"imdbHeader-navDrawerOpen\"]')\n",
    "menu.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7b54fa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore = driver.find_element(By.XPATH,'//*[@id=\"imdbHeader\"]/div[2]/aside[1]/div/div[2]/div/div[2]/div[1]/span/div/div/ul/a[3]/span')\n",
    "explore.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3e19deff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty enumerates for store details\n",
    "name = []\n",
    "year = []\n",
    "run_time = []\n",
    "genre = []\n",
    "ratings = []\n",
    "votes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "db32221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap name\n",
    "names = driver.find_elements(By.XPATH,'//div[@class=\"ipc-title ipc-title--base ipc-title--title ipc-title-link-no-icon ipc-title--on-textPrimary sc-43986a27-9 gaoUku dli-title\"]')\n",
    "for i in names:\n",
    "    name.append(i.text)\n",
    "    \n",
    "# scrap year\n",
    "years = driver.find_elements(By.XPATH,'//div[@class=\"sc-43986a27-7 dBkaPT dli-title-metadata\"]//span[1]')\n",
    "for a in years:\n",
    "    year.append(a.text)\n",
    "    \n",
    "# scrap run time\n",
    "episode = driver.find_elements(By.XPATH,'//div[@class=\"sc-43986a27-7 dBkaPT dli-title-metadata\"]//span[2]')\n",
    "for b in episode:\n",
    "    run_time.append(b.text)\n",
    "    \n",
    "# scrap genre\n",
    "gen = driver.find_elements(By.XPATH,'//div[@class=\"sc-43986a27-7 dBkaPT dli-title-metadata\"]//span[3]')\n",
    "for c in gen:\n",
    "    genre.append(c.text)\n",
    "    \n",
    "# scrap ratings\n",
    "rat = driver.find_elements(By.XPATH,'//span[@class=\"ipc-rating-star ipc-rating-star--base ipc-rating-star--imdb sc-9ab53865-1 iXEijC ratingGroup--imdb-rating\"]')\n",
    "for d in rat:\n",
    "    ratings.append(d.text)\n",
    "    \n",
    "# scrap votes\n",
    "vote = driver.find_elements(By.XPATH,'//div[@class=\"sc-53c98e73-0 kRnqtn\"]')\n",
    "for e in vote:\n",
    "    votes.append(e.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "108f8a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Years</th>\n",
       "      <th>Run_time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reacher</td>\n",
       "      <td>2022–</td>\n",
       "      <td>17 eps</td>\n",
       "      <td>8.1\\n (167K)</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>Votes166,612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Percy Jackson and the Olympians</td>\n",
       "      <td>2023–</td>\n",
       "      <td>8 eps</td>\n",
       "      <td>7.7\\n (6.8K)</td>\n",
       "      <td>TV-PG</td>\n",
       "      <td>Votes6,804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Crown</td>\n",
       "      <td>2016–2023</td>\n",
       "      <td>60 eps</td>\n",
       "      <td>8.6\\n (245K)</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>Votes245,094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fargo</td>\n",
       "      <td>2014–2024</td>\n",
       "      <td>51 eps</td>\n",
       "      <td>8.9\\n (400K)</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>Votes400,292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Doctor Who</td>\n",
       "      <td>2005–</td>\n",
       "      <td>196 eps</td>\n",
       "      <td>8.6\\n (242K)</td>\n",
       "      <td>TV-PG</td>\n",
       "      <td>Votes241,734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>The Witcher</td>\n",
       "      <td>2019–</td>\n",
       "      <td>31 eps</td>\n",
       "      <td>8.2\\n (124K)</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>Votes124,159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>The Morning Show</td>\n",
       "      <td>2019–</td>\n",
       "      <td>16 eps</td>\n",
       "      <td>8.3\\n (12K)</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>Votes11,545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Julia</td>\n",
       "      <td>2022–</td>\n",
       "      <td>6 eps</td>\n",
       "      <td>6.9\\n (8.4K)</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>Votes8,391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>A Nearly Normal Family</td>\n",
       "      <td>2023</td>\n",
       "      <td>217 eps</td>\n",
       "      <td>8.6\\n (244K)</td>\n",
       "      <td>TV-PG</td>\n",
       "      <td>Votes243,874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>The X-Files</td>\n",
       "      <td>1993–2018</td>\n",
       "      <td>173 eps</td>\n",
       "      <td>8.9\\n (344K)</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>Votes343,655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Name      Years Run_time       Ratings  Genre  \\\n",
       "0                           Reacher      2022–   17 eps  8.1\\n (167K)  TV-MA   \n",
       "1   Percy Jackson and the Olympians      2023–    8 eps  7.7\\n (6.8K)  TV-PG   \n",
       "2                         The Crown  2016–2023   60 eps  8.6\\n (245K)  TV-MA   \n",
       "3                             Fargo  2014–2024   51 eps  8.9\\n (400K)  TV-MA   \n",
       "4                        Doctor Who      2005–  196 eps  8.6\\n (242K)  TV-PG   \n",
       "..                              ...        ...      ...           ...    ...   \n",
       "85                      The Witcher      2019–   31 eps  8.2\\n (124K)  TV-MA   \n",
       "86                 The Morning Show      2019–   16 eps   8.3\\n (12K)  TV-MA   \n",
       "87                            Julia      2022–    6 eps  6.9\\n (8.4K)  TV-14   \n",
       "88           A Nearly Normal Family       2023  217 eps  8.6\\n (244K)  TV-PG   \n",
       "89                      The X-Files  1993–2018  173 eps  8.9\\n (344K)  TV-MA   \n",
       "\n",
       "           Votes  \n",
       "0   Votes166,612  \n",
       "1     Votes6,804  \n",
       "2   Votes245,094  \n",
       "3   Votes400,292  \n",
       "4   Votes241,734  \n",
       "..           ...  \n",
       "85  Votes124,159  \n",
       "86   Votes11,545  \n",
       "87    Votes8,391  \n",
       "88  Votes243,874  \n",
       "89  Votes343,655  \n",
       "\n",
       "[90 rows x 6 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe\n",
    "data=pd.DataFrame({})\n",
    "data['Name']= name[:90]\n",
    "data['Years']= year[:90]\n",
    "data['Run_time']= run_time[:90]\n",
    "data['Ratings']= ratings[:90]\n",
    "data['Genre']= genre[:90]\n",
    "data['Votes']= votes[:90]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "006c8b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa0694c",
   "metadata": {},
   "source": [
    "**Question 8**- Details of Datasets from UCI machine learning repositories.\n",
    "\n",
    "Url = https://archive.ics.uci.edu/\n",
    "    \n",
    "Youhave to find the following details:\n",
    "- Dataset name\n",
    "- Data type\n",
    "- Task\n",
    "- Attribute type\n",
    "- No of instances\n",
    "- No of attribute \n",
    "- Year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22e3c01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import selenium\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4dffeac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the archive.ics.uci.edu page on automated chrome browser\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "064bec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://archive.ics.uci.edu/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9cf035b",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_all = driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]')\n",
    "view_all.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7af78e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "expand_data = driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[1]/div/label[2]/div[2]/span[2]')\n",
    "expand_data.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d8a6195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty enumerate for store a details\n",
    "dataset_name = []\n",
    "data_type = []\n",
    "tasks = []\n",
    "attribute_type = []\n",
    "instance = []\n",
    "num_attributes = []\n",
    "year = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2233b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap dataset names\n",
    "data = driver.find_elements(By.XPATH,'//h2[@class=\"truncate text-primary\"]')\n",
    "for i in data:\n",
    "    dataset_name.append(i.text)\n",
    "    \n",
    "# scrap data types\n",
    "types = driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[2]')\n",
    "for a in types:\n",
    "    data_type.append(a.text)\n",
    "    \n",
    "# scrap tasks\n",
    "task = driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[1]')\n",
    "for b in task:\n",
    "    tasks.append(b.text)\n",
    "    \n",
    "    \n",
    "# scrap attribute type    \n",
    "attribute = driver.find_elements(By.XPATH,'//tbody[@class=\"border\"]//td[2]')\n",
    "for c in attribute:\n",
    "    attribute_type.append(c.text)\n",
    "    \n",
    "# scrap instance\n",
    "ins = driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[3]')\n",
    "for d in ins:\n",
    "    instance.append(d.text)\n",
    "    \n",
    "# scrap number of attribute\n",
    "noa = driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[4]')\n",
    "for e in noa:\n",
    "    num_attributes.append(e.text)\n",
    "    \n",
    "# scrap years\n",
    "years = driver.find_elements(By.XPATH,'//tbody[@class=\"border\"]//td[3]')\n",
    "for f in years:\n",
    "    year.append(f.text)\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6ff6772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_name),len(data_type),len(tasks),len(attribute_type),len(instance),len(num_attributes),len(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84e3daae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Tasks</th>\n",
       "      <th>Attribute Types</th>\n",
       "      <th>Instance</th>\n",
       "      <th>No.of attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150 Instances</td>\n",
       "      <td>4 Features</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13.61K Instances</td>\n",
       "      <td>16 Features</td>\n",
       "      <td>9/14/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>3.81K Instances</td>\n",
       "      <td>7 Features</td>\n",
       "      <td>10/6/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>14 Features</td>\n",
       "      <td>5/1/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>7/1/1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569 Instances</td>\n",
       "      <td>30 Features</td>\n",
       "      <td>11/1/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>1 Instances</td>\n",
       "      <td>20 Features</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wine Quality</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4.9K Instances</td>\n",
       "      <td>12 Features</td>\n",
       "      <td>10/7/2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1.73K Instances</td>\n",
       "      <td>6 Features</td>\n",
       "      <td>6/1/1997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Dataset Name                  Data Type  \\\n",
       "0                                  Iris                    Tabular   \n",
       "1                      Dry Bean Dataset               Multivariate   \n",
       "2            Rice (Cammeo and Osmancik)               Multivariate   \n",
       "3                         Heart Disease               Multivariate   \n",
       "4                                 Adult               Multivariate   \n",
       "5                                  Wine                    Tabular   \n",
       "6  Breast Cancer Wisconsin (Diagnostic)               Multivariate   \n",
       "7                              Diabetes  Multivariate, Time-Series   \n",
       "8                          Wine Quality               Multivariate   \n",
       "9                        Car Evaluation               Multivariate   \n",
       "\n",
       "                        Tasks             Attribute Types          Instance  \\\n",
       "0              Classification                        Real     150 Instances   \n",
       "1              Classification               Integer, Real  13.61K Instances   \n",
       "2              Classification                        Real   3.81K Instances   \n",
       "3              Classification  Categorical, Integer, Real     303 Instances   \n",
       "4              Classification        Categorical, Integer  48.84K Instances   \n",
       "5              Classification               Integer, Real     178 Instances   \n",
       "6              Classification                        Real     569 Instances   \n",
       "7              Classification        Categorical, Integer       1 Instances   \n",
       "8  Classification, Regression                        Real    4.9K Instances   \n",
       "9              Classification                 Categorical   1.73K Instances   \n",
       "\n",
       "  No.of attribute       Year  \n",
       "0      4 Features   7/1/1988  \n",
       "1     16 Features  9/14/2020  \n",
       "2      7 Features  10/6/2019  \n",
       "3     13 Features   7/1/1988  \n",
       "4     14 Features   5/1/1996  \n",
       "5     13 Features   7/1/1991  \n",
       "6     30 Features  11/1/1995  \n",
       "7     20 Features        N/A  \n",
       "8     12 Features  10/7/2009  \n",
       "9      6 Features   6/1/1997  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe\n",
    "data=pd.DataFrame({})\n",
    "data['Dataset Name']= dataset_name\n",
    "data['Data Type']= data_type\n",
    "data['Tasks']= tasks\n",
    "data['Attribute Types']= attribute_type\n",
    "data['Instance']= instance\n",
    "data ['No.of attribute']= num_attributes\n",
    "data ['Year']= year\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f686a42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
